{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19450b7f",
   "metadata": {},
   "source": [
    "# Short-Term Memory (InMemorySaver) in LangGraph\n",
    "\n",
    "This notebook demonstrates how **short-term memory** works in LangGraph using `InMemorySaver`.\n",
    "\n",
    "## What is Short-Term Memory?\n",
    "\n",
    "**Short-term memory** in LangGraph refers to storing conversation history and state **temporarily in RAM**:\n",
    "- ‚úÖ Data persists **during program execution**\n",
    "- ‚ùå Data is **lost when program stops/restarts**\n",
    "- ‚ö° Very fast (no disk I/O)\n",
    "- üéØ Perfect for development, testing, and temporary sessions\n",
    "\n",
    "## Use Case: Customer Support Chatbot\n",
    "\n",
    "We'll build a chatbot that:\n",
    "1. Remembers conversation history within a session\n",
    "2. Can handle multiple users simultaneously (different threads)\n",
    "3. Provides context-aware responses based on chat history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fb2f3b",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbb36d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from typing import TypedDict, Annotated, List\n",
    "import operator\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from euriai.langchain import create_chat_model\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b544575b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_model = create_chat_model(\n",
    "    api_key=api_key,\n",
    "    model=\"gpt-4.1-nano\",\n",
    "    temperature=0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eea8ce0",
   "metadata": {},
   "source": [
    "## Step 2: Define State with Message History\n",
    "\n",
    "Key point: We use `Annotated[List[str], operator.add]` to **accumulate** messages instead of overwriting them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ba82fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatState(TypedDict):\n",
    "    # Annotated[List[str], operator.add] ensures messages ACCUMULATE across turns\n",
    "    # Each new message is APPENDED to the list, not replaced\n",
    "    messages: Annotated[List[str], operator.add]\n",
    "    \n",
    "    # Current user input\n",
    "    user_input: str\n",
    "    \n",
    "    # AI response\n",
    "    ai_response: str\n",
    "    \n",
    "    # User name for personalization\n",
    "    user_name: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8756a14",
   "metadata": {},
   "source": [
    "## Step 3: Create Workflow Nodes\n",
    "\n",
    "We'll create nodes that:\n",
    "1. Process user input and add to history\n",
    "2. Generate AI response based on conversation history\n",
    "3. Store the response in history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc227eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_user_message(state: ChatState):\n",
    "    \"\"\"Add user message to conversation history\"\"\"\n",
    "    user_input = state['user_input']\n",
    "    user_name = state.get('user_name', 'User')\n",
    "    \n",
    "    # Format message with user name\n",
    "    formatted_message = f\"{user_name}: {user_input}\"\n",
    "    \n",
    "    # This will be appended to messages list due to operator.add\n",
    "    return {\"messages\": [formatted_message]}\n",
    "\n",
    "def generate_response(state: ChatState):\n",
    "    \"\"\"Generate AI response based on conversation history\"\"\"\n",
    "    \n",
    "    # Get conversation history\n",
    "    conversation_history = state.get('messages', [])\n",
    "    user_name = state.get('user_name', 'User')\n",
    "    \n",
    "    # Build context from history\n",
    "    if conversation_history:\n",
    "        context = \"\\n\".join(conversation_history)\n",
    "        prompt = f\"\"\"You are a helpful customer support assistant. \n",
    "        \n",
    "        Previous conversation:\n",
    "        {context}\n",
    "        Please provide a helpful and context-aware response to the latest message. Be friendly and reference previous conversation when relevant.\"\"\"\n",
    "        \n",
    "    else:\n",
    "        prompt = f\"You are a helpful customer support assistant. Please respond to: {state['user_input']}\"\n",
    "    \n",
    "    # Generate response\n",
    "    ai_response = chat_model.invoke(prompt).content\n",
    "    \n",
    "    # Format AI message\n",
    "    formatted_response = f\"Assistant: {ai_response}\"\n",
    "    \n",
    "    # Return both the response and add it to messages history\n",
    "    return {\n",
    "        \"ai_response\": ai_response,\n",
    "        \"messages\": [formatted_response]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0581d53",
   "metadata": {},
   "source": [
    "## Step 4: Build the Graph with InMemorySaver\n",
    "\n",
    "**Key: We use `InMemorySaver()` as the checkpointer** - this enables short-term memory!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f332e217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Workflow compiled with InMemorySaver (short-term memory enabled)\n"
     ]
    }
   ],
   "source": [
    "# Create the graph\n",
    "graph = StateGraph(ChatState)\n",
    "\n",
    "# Add nodes\n",
    "graph.add_node(\"process_user_message\", process_user_message)\n",
    "graph.add_node(\"generate_response\", generate_response)\n",
    "\n",
    "# Add edges\n",
    "graph.add_edge(START, \"process_user_message\")\n",
    "graph.add_edge(\"process_user_message\", \"generate_response\")\n",
    "graph.add_edge(\"generate_response\", END)\n",
    "\n",
    "# ‚≠ê Create InMemorySaver - this is the SHORT-TERM MEMORY\n",
    "checkpointer = InMemorySaver()\n",
    "\n",
    "# Compile with checkpointer\n",
    "workflow = graph.compile(checkpointer=checkpointer)\n",
    "\n",
    "print(\"‚úÖ Workflow compiled with InMemorySaver (short-term memory enabled)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40f6f584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize the workflow\n",
    "from IPython.display import Image\n",
    "Image(workflow.get_graph().draw_mermaid_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5e5a4c",
   "metadata": {},
   "source": [
    "## Step 5: Test Short-Term Memory - Single User Conversation\n",
    "\n",
    "Let's simulate a conversation where the chatbot **remembers** previous messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e4d5c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to chat\n",
    "def chat(user_input: str, thread_id: str, user_name: str = \"User\"):\n",
    "    \"\"\"Send a message and get response\"\"\"\n",
    "    config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "    \n",
    "    result = workflow.invoke(\n",
    "        {\n",
    "            \"user_input\": user_input,\n",
    "            \"user_name\": user_name\n",
    "        },\n",
    "        config=config\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n{user_name}: {user_input}\")\n",
    "    print(f\"Assistant: {result['ai_response']}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ef9ea4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CONVERSATION WITH ALICE (Thread: alice_001)\n",
      "================================================================================\n",
      "\n",
      "Alice: Hi! I need help with my order\n",
      "Assistant: Hello Alice! I'd be happy to assist you with your order. Could you please provide me with your order number or let me know what specific issue you're experiencing? I'm here to help!\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': ['Alice: Hi! I need help with my order',\n",
       "  \"Assistant: Hello Alice! I'd be happy to assist you with your order. Could you please provide me with your order number or let me know what specific issue you're experiencing? I'm here to help!\"],\n",
       " 'user_input': 'Hi! I need help with my order',\n",
       " 'ai_response': \"Hello Alice! I'd be happy to assist you with your order. Could you please provide me with your order number or let me know what specific issue you're experiencing? I'm here to help!\",\n",
       " 'user_name': 'Alice'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Conversation 1: User Alice - Thread 1\n",
    "print(\"=\" * 80)\n",
    "print(\"CONVERSATION WITH ALICE (Thread: alice_001)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# First message\n",
    "chat(\"Hi! I need help with my order\", \"alice_001\", \"Alice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8055a137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Alice: My order number is #12345\n",
      "Assistant: Hello Alice! Thank you for providing your order number #12345. Could you please let me know what specific issue you're experiencing with your order? Whether it's a delay, a missing item, or anything else, I'm here to help!\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': ['Alice: Hi! I need help with my order',\n",
       "  \"Assistant: Hello Alice! I'd be happy to assist you with your order. Could you please provide me with your order number or let me know what specific issue you're experiencing? I'm here to help!\",\n",
       "  'Alice: My order number is #12345',\n",
       "  \"Assistant: Hello Alice! Thank you for providing your order number #12345. Could you please let me know what specific issue you're experiencing with your order? Whether it's a delay, a missing item, or anything else, I'm here to help!\"],\n",
       " 'user_input': 'My order number is #12345',\n",
       " 'ai_response': \"Hello Alice! Thank you for providing your order number #12345. Could you please let me know what specific issue you're experiencing with your order? Whether it's a delay, a missing item, or anything else, I'm here to help!\",\n",
       " 'user_name': 'Alice'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Second message - AI should remember the first message!\n",
    "chat(\"My order number is #12345\", \"alice_001\", \"Alice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c85319a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Alice: When will it arrive?\n",
      "Assistant: Hello Alice! Thank you for your message. Based on your order #12345, I will check the estimated delivery date for you. Please hold on a moment while I look up the details.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': ['Alice: Hi! I need help with my order',\n",
       "  \"Assistant: Hello Alice! I'd be happy to assist you with your order. Could you please provide me with your order number or let me know what specific issue you're experiencing? I'm here to help!\",\n",
       "  'Alice: My order number is #12345',\n",
       "  \"Assistant: Hello Alice! Thank you for providing your order number #12345. Could you please let me know what specific issue you're experiencing with your order? Whether it's a delay, a missing item, or anything else, I'm here to help!\",\n",
       "  'Alice: When will it arrive?',\n",
       "  'Assistant: Hello Alice! Thank you for your message. Based on your order #12345, I will check the estimated delivery date for you. Please hold on a moment while I look up the details.'],\n",
       " 'user_input': 'When will it arrive?',\n",
       " 'ai_response': 'Hello Alice! Thank you for your message. Based on your order #12345, I will check the estimated delivery date for you. Please hold on a moment while I look up the details.',\n",
       " 'user_name': 'Alice'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Third message - AI should remember entire conversation!\n",
    "chat(\"When will it arrive?\", \"alice_001\", \"Alice\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ea2ceb",
   "metadata": {},
   "source": [
    "## Step 6: View Conversation History\n",
    "\n",
    "Let's inspect what's stored in short-term memory for Alice's conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f26a44b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Alice's Current State:\n",
      "\n",
      "Messages History:\n",
      "1. Alice: Hi! I need help with my order\n",
      "2. Assistant: Hello Alice! I'd be happy to assist you with your order. Could you please provide me with your order number or let me know what specific issue you're experiencing? I'm here to help!\n",
      "3. Alice: My order number is #12345\n",
      "4. Assistant: Hello Alice! Thank you for providing your order number #12345. Could you please let me know what specific issue you're experiencing with your order? Whether it's a delay, a missing item, or anything else, I'm here to help!\n",
      "5. Alice: When will it arrive?\n",
      "6. Assistant: Hello Alice! Thank you for your message. Based on your order #12345, I will check the estimated delivery date for you. Please hold on a moment while I look up the details.\n",
      "\n",
      "Last AI Response: Hello Alice! Thank you for your message. Based on your order #12345, I will check the estimated delivery date for you. Please hold on a moment while I look up the details.\n"
     ]
    }
   ],
   "source": [
    "# Get current state for Alice's thread\n",
    "alice_config = {\"configurable\": {\"thread_id\": \"alice_001\"}}\n",
    "alice_state = workflow.get_state(config=alice_config)\n",
    "\n",
    "print(\"üìù Alice's Current State:\")\n",
    "print(\"\\nMessages History:\")\n",
    "for i, msg in enumerate(alice_state.values.get('messages', []), 1):\n",
    "    print(f\"{i}. {msg}\")\n",
    "\n",
    "print(f\"\\nLast AI Response: {alice_state.values.get('ai_response', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8b582a",
   "metadata": {},
   "source": [
    "## Step 7: Multiple Users - Separate Threads\n",
    "\n",
    "Short-term memory keeps conversations **isolated** by thread_id. Let's test with another user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8f25b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "CONVERSATION WITH BOB (Thread: bob_002)\n",
      "================================================================================\n",
      "\n",
      "Bob: Hello! Can I get a refund?\n",
      "Assistant: Hello Bob! I'd be happy to assist you with your refund request. Could you please provide some details about the purchase you'd like to refund? Once I have that information, I can guide you through the process.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': ['Bob: Hello! Can I get a refund?',\n",
       "  \"Assistant: Hello Bob! I'd be happy to assist you with your refund request. Could you please provide some details about the purchase you'd like to refund? Once I have that information, I can guide you through the process.\"],\n",
       " 'user_input': 'Hello! Can I get a refund?',\n",
       " 'ai_response': \"Hello Bob! I'd be happy to assist you with your refund request. Could you please provide some details about the purchase you'd like to refund? Once I have that information, I can guide you through the process.\",\n",
       " 'user_name': 'Bob'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Conversation 2: User Bob - Thread 2 (completely separate from Alice)\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CONVERSATION WITH BOB (Thread: bob_002)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "chat(\"Hello! Can I get a refund?\", \"bob_002\", \"Bob\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4089f9a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bob: I bought a laptop last week\n",
      "Assistant: Hello Bob! Thanks for sharing that you bought a laptop last week. To assist you further with your refund request, could you please confirm if you still have the receipt or order number? Additionally, if there are any specific issues with the laptop or reasons for the refund, please let me know. I'm here to help you through the process!\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': ['Bob: Hello! Can I get a refund?',\n",
       "  \"Assistant: Hello Bob! I'd be happy to assist you with your refund request. Could you please provide some details about the purchase you'd like to refund? Once I have that information, I can guide you through the process.\",\n",
       "  'Bob: I bought a laptop last week',\n",
       "  \"Assistant: Hello Bob! Thanks for sharing that you bought a laptop last week. To assist you further with your refund request, could you please confirm if you still have the receipt or order number? Additionally, if there are any specific issues with the laptop or reasons for the refund, please let me know. I'm here to help you through the process!\"],\n",
       " 'user_input': 'I bought a laptop last week',\n",
       " 'ai_response': \"Hello Bob! Thanks for sharing that you bought a laptop last week. To assist you further with your refund request, could you please confirm if you still have the receipt or order number? Additionally, if there are any specific issues with the laptop or reasons for the refund, please let me know. I'm here to help you through the process!\",\n",
       " 'user_name': 'Bob'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bob's second message\n",
    "chat(\"I bought a laptop last week\", \"bob_002\", \"Bob\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12398f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Bob's Current State:\n",
      "\n",
      "Messages History:\n",
      "1. Bob: Hello! Can I get a refund?\n",
      "2. Assistant: Hello Bob! I'd be happy to assist you with your refund request. Could you please provide some details about the purchase you'd like to refund? Once I have that information, I can guide you through the process.\n",
      "3. Bob: I bought a laptop last week\n",
      "4. Assistant: Hello Bob! Thanks for sharing that you bought a laptop last week. To assist you further with your refund request, could you please confirm if you still have the receipt or order number? Additionally, if there are any specific issues with the laptop or reasons for the refund, please let me know. I'm here to help you through the process!\n"
     ]
    }
   ],
   "source": [
    "# Check Bob's state - should be different from Alice's\n",
    "bob_config = {\"configurable\": {\"thread_id\": \"bob_002\"}}\n",
    "bob_state = workflow.get_state(config=bob_config)\n",
    "\n",
    "print(\"üìù Bob's Current State:\")\n",
    "print(\"\\nMessages History:\")\n",
    "for i, msg in enumerate(bob_state.values.get('messages', []), 1):\n",
    "    print(f\"{i}. {msg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfd277a",
   "metadata": {},
   "source": [
    "## Step 8: Compare Both Conversations\n",
    "\n",
    "Let's verify that both conversations are **completely isolated** in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2101393c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "COMPARISON: Alice vs Bob\n",
      "================================================================================\n",
      "\n",
      "üë© ALICE'S CONVERSATION:\n",
      "----------------------------------------\n",
      "Alice: Hi! I need help with my order\n",
      "Assistant: Hello Alice! I'd be happy to assist you with your order. Could you please provide me with your order number or let me know what specific issue you're experiencing? I'm here to help!\n",
      "Alice: My order number is #12345\n",
      "Assistant: Hello Alice! Thank you for providing your order number #12345. Could you please let me know what specific issue you're experiencing with your order? Whether it's a delay, a missing item, or anything else, I'm here to help!\n",
      "Alice: When will it arrive?\n",
      "Assistant: Hello Alice! Thank you for your message. Based on your order #12345, I will check the estimated delivery date for you. Please hold on a moment while I look up the details.\n",
      "\n",
      "\n",
      "üë® BOB'S CONVERSATION:\n",
      "----------------------------------------\n",
      "Bob: Hello! Can I get a refund?\n",
      "Assistant: Hello Bob! I'd be happy to assist you with your refund request. Could you please provide some details about the purchase you'd like to refund? Once I have that information, I can guide you through the process.\n",
      "Bob: I bought a laptop last week\n",
      "Assistant: Hello Bob! Thanks for sharing that you bought a laptop last week. To assist you further with your refund request, could you please confirm if you still have the receipt or order number? Additionally, if there are any specific issues with the laptop or reasons for the refund, please let me know. I'm here to help you through the process!\n",
      "\n",
      "‚úÖ Both conversations are completely isolated!\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"COMPARISON: Alice vs Bob\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "alice_state = workflow.get_state(config={\"configurable\": {\"thread_id\": \"alice_001\"}})\n",
    "bob_state = workflow.get_state(config={\"configurable\": {\"thread_id\": \"bob_002\"}})\n",
    "\n",
    "print(\"\\nüë© ALICE'S CONVERSATION:\")\n",
    "print(\"-\" * 40)\n",
    "for msg in alice_state.values.get('messages', []):\n",
    "    print(msg)\n",
    "\n",
    "print(\"\\n\\nüë® BOB'S CONVERSATION:\")\n",
    "print(\"-\" * 40)\n",
    "for msg in bob_state.values.get('messages', []):\n",
    "    print(msg)\n",
    "\n",
    "print(\"\\n‚úÖ Both conversations are completely isolated!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78edac27",
   "metadata": {},
   "source": [
    "## Step 9: View Full History for a Thread\n",
    "\n",
    "We can see **every checkpoint** (state snapshot) in the conversation history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb342e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìö Alice's conversation has 12 checkpoints\n",
      "\n",
      "Checkpoint 1:\n",
      "  Messages count: 6\n",
      "  Last user input: When will it arrive?\n",
      "  Node: ()\n",
      "------------------------------------------------------------\n",
      "Checkpoint 2:\n",
      "  Messages count: 5\n",
      "  Last user input: When will it arrive?\n",
      "  Node: ('generate_response',)\n",
      "------------------------------------------------------------\n",
      "Checkpoint 3:\n",
      "  Messages count: 4\n",
      "  Last user input: When will it arrive?\n",
      "  Node: ('process_user_message',)\n",
      "------------------------------------------------------------\n",
      "Checkpoint 4:\n",
      "  Messages count: 4\n",
      "  Last user input: My order number is #12345\n",
      "  Node: ('__start__',)\n",
      "------------------------------------------------------------\n",
      "Checkpoint 5:\n",
      "  Messages count: 4\n",
      "  Last user input: My order number is #12345\n",
      "  Node: ()\n",
      "------------------------------------------------------------\n",
      "Checkpoint 6:\n",
      "  Messages count: 3\n",
      "  Last user input: My order number is #12345\n",
      "  Node: ('generate_response',)\n",
      "------------------------------------------------------------\n",
      "Checkpoint 7:\n",
      "  Messages count: 2\n",
      "  Last user input: My order number is #12345\n",
      "  Node: ('process_user_message',)\n",
      "------------------------------------------------------------\n",
      "Checkpoint 8:\n",
      "  Messages count: 2\n",
      "  Last user input: Hi! I need help with my order\n",
      "  Node: ('__start__',)\n",
      "------------------------------------------------------------\n",
      "Checkpoint 9:\n",
      "  Messages count: 2\n",
      "  Last user input: Hi! I need help with my order\n",
      "  Node: ()\n",
      "------------------------------------------------------------\n",
      "Checkpoint 10:\n",
      "  Messages count: 1\n",
      "  Last user input: Hi! I need help with my order\n",
      "  Node: ('generate_response',)\n",
      "------------------------------------------------------------\n",
      "Checkpoint 11:\n",
      "  Messages count: 0\n",
      "  Last user input: Hi! I need help with my order\n",
      "  Node: ('process_user_message',)\n",
      "------------------------------------------------------------\n",
      "Checkpoint 12:\n",
      "  Messages count: 0\n",
      "  Last user input: N/A\n",
      "  Node: ('__start__',)\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Get full history for Alice's thread\n",
    "alice_history = list(workflow.get_state_history(config={\"configurable\": {\"thread_id\": \"alice_001\"}}))\n",
    "\n",
    "print(f\"üìö Alice's conversation has {len(alice_history)} checkpoints\\n\")\n",
    "\n",
    "# Show each checkpoint (in reverse chronological order)\n",
    "for i, checkpoint in enumerate(alice_history):\n",
    "    print(f\"Checkpoint {i + 1}:\")\n",
    "    print(f\"  Messages count: {len(checkpoint.values.get('messages', []))}\")\n",
    "    print(f\"  Last user input: {checkpoint.values.get('user_input', 'N/A')}\")\n",
    "    print(f\"  Node: {checkpoint.next}\")\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e581697",
   "metadata": {},
   "source": [
    "## Step 10: What Happens When Program Restarts?\n",
    "\n",
    "‚ö†Ô∏è **Important Limitation of InMemorySaver (Short-Term Memory):**\n",
    "\n",
    "```python\n",
    "# If you restart this notebook kernel:\n",
    "# 1. All conversation history is LOST ‚ùå\n",
    "# 2. Alice's and Bob's threads are GONE ‚ùå\n",
    "# 3. You start fresh with empty memory\n",
    "```\n",
    "\n",
    "**Why?** Because `InMemorySaver` stores data in RAM, which is cleared on restart.\n",
    "\n",
    "**Solution for Persistence:**\n",
    "```python\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "\n",
    "# Use SqliteSaver instead - data survives restarts! ‚úÖ\n",
    "checkpointer = SqliteSaver.from_conn_string(\"chat_history.db\")\n",
    "workflow = graph.compile(checkpointer=checkpointer)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24bd899",
   "metadata": {},
   "source": [
    "## Summary: InMemorySaver (Short-Term Memory)\n",
    "\n",
    "### ‚úÖ What It Does:\n",
    "1. **Stores conversation state in RAM** during program execution\n",
    "2. **Isolates conversations** by `thread_id`\n",
    "3. **Accumulates messages** across turns using `Annotated[List, operator.add]`\n",
    "4. **Provides context** for AI to generate relevant responses\n",
    "5. **Very fast** - no disk I/O\n",
    "\n",
    "### ‚ùå Limitations:\n",
    "1. **Data lost on restart** - not persistent\n",
    "2. **Not suitable for production** if you need conversation history across sessions\n",
    "3. **Limited by RAM** - can't scale indefinitely\n",
    "\n",
    "### üéØ Best Use Cases:\n",
    "- Development and testing\n",
    "- Temporary chat sessions\n",
    "- Demos and prototypes\n",
    "- Single-session workflows\n",
    "\n",
    "### üîÑ Alternatives:\n",
    "- **SqliteSaver** - File-based persistence\n",
    "- **PostgresSaver** - Database persistence for production\n",
    "- **RedisSaver** - Fast distributed caching\n",
    "\n",
    "---\n",
    "\n",
    "**Key Takeaway:** `InMemorySaver` is perfect for **temporary, fast, in-session memory** but not for long-term persistence! üß†üí®"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
